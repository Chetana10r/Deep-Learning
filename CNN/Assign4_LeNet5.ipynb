{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d92632a2",
   "metadata": {},
   "source": [
    "1. Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27d52930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440e0ae7",
   "metadata": {},
   "source": [
    "2. Pre-processing and Normalizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e7f5695",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 28, 28\n",
    "\n",
    "# Reshape the data into a 4D Array\n",
    "x_train = x_train.reshape(x_train.shape[0], rows, cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], rows, cols, 1)\n",
    "\n",
    "input_shape = (rows,cols,1) \n",
    "\n",
    "# Set type as float32 and normalize the values to [0,1]\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Transform labels to one hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8790b0cd",
   "metadata": {},
   "source": [
    "3. Define LeNet-5 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67c50ef",
   "metadata": {},
   "source": [
    "Create a new instance of a model object using sequential model API. Then add layers to the neural network as per the LeNet-5 architecture discussed earlier. Finally, compile the model with the ‘categorical_crossentropy’ loss function and ‘SGD’ cost optimization algorithm. When compiling the model, add metrics=[‘accuracy’] as one of the parameters to calculate the accuracy of the model.\n",
    "\n",
    "It is important to highlight that each image in the MNIST data set has a size of 28 X 28 pixels so we will use the same dimensions for LeNet-5 input instead of 32 X 32 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57f2292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lenet(input_shape):\n",
    "  # Define Sequential Model\n",
    "  model = tf.keras.Sequential()\n",
    "\n",
    "  # C1 Convolution Layer\n",
    "  model.add(tf.keras.layers.Conv2D(filters=6, strides=(1,1), kernel_size=(5,5), activation='tanh', input_shape=input_shape))\n",
    "\n",
    "  # S2 SubSampling Layer\n",
    "  model.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "  # C3 Convolution Layer\n",
    "  model.add(tf.keras.layers.Conv2D(filters=6, strides=(1,1), kernel_size=(5,5), activation='tanh'))\n",
    "\n",
    "  # S4 SubSampling Layer\n",
    "  model.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "  # C5 Fully Connected Layer\n",
    "  model.add(tf.keras.layers.Dense(units=120, activation='tanh'))\n",
    "\n",
    "  # Flatten the output so that we can connect it with the fully connected layers by converting it into a 1D Array\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "  # FC6 Fully Connected Layers\n",
    "  model.add(tf.keras.layers.Dense(units=84, activation='tanh'))\n",
    "\n",
    "  # Output Layer\n",
    "  model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb10bd7",
   "metadata": {},
   "source": [
    "4. Evaluate the Model and Visualize the process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8141d8a0",
   "metadata": {},
   "source": [
    "We can train the model by calling the model.fit function and pass in the training data, the expected output, the number of epochs, and batch size. Additionally, Keras provides a facility to evaluate the loss and accuracy at the end of each epoch. For this purpose, we can split the training data using the ‘validation_split’ argument or use another dataset using the ‘validation_data’ argument. We will use our training dataset to evaluate the loss and accuracy after every epoch.\n",
    "\n",
    "We can test the model by calling model.evaluate and passing in the testing data set and the expected output. We will visualize the training process by plotting the training accuracy and loss after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4daec65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cheta\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9049 - loss: 0.3309\n",
      "Epoch 2/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9575 - loss: 0.1410\n",
      "Epoch 3/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9713 - loss: 0.0955\n",
      "Epoch 4/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0745\n",
      "Epoch 5/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9816 - loss: 0.0610\n",
      "Epoch 6/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9837 - loss: 0.0535\n",
      "Epoch 7/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9858 - loss: 0.0462\n",
      "Epoch 8/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9876 - loss: 0.0412\n",
      "Epoch 9/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9887 - loss: 0.0375\n",
      "Epoch 10/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9901 - loss: 0.0332\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.0467\n",
      "Accuracy :  0.9839000105857849\n",
      "Training Data (60000, 28, 28) (60000, 10)\n",
      "Test Data (10000, 28, 28) (10000, 10)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lenet = build_lenet(input_shape)\n",
    "\n",
    "# Compile the model\n",
    "lenet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# We will be allowing 10 itterations to happen\n",
    "epochs = 10\n",
    "history = lenet.fit(x_train, y_train, epochs=epochs,batch_size=128, verbose=1)\n",
    "\n",
    "# Check Accuracy of the Model\n",
    "# Transform labels to one hot encoding\n",
    "if len(y_test.shape) != 2 or y_test.shape[1] != 10:\n",
    "  y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "loss ,acc= lenet.evaluate(x_test, y_test)\n",
    "print('Accuracy : ', acc)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28,28)\n",
    "print('Training Data', x_train.shape, y_train.shape)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28,28)\n",
    "print('Test Data', x_test.shape, y_test.shape)\n",
    "\n",
    "# Plot the Image\n",
    "image_index = 8888\n",
    "plt.imshow(x_test[image_index].reshape(28,28), cmap='Greys')\n",
    "\n",
    "# Make Prediction\n",
    "pred = lenet.predict(x_test[image_index].reshape(1, rows, cols, 1 ))\n",
    "print(pred.argmax())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
